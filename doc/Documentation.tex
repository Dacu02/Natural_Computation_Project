\documentclass[11pt]{article}

% \usepackage[utf-8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{longtable}
\usepackage[style=numeric, backend=bibtex]{biblatex}
\addbibresource{Documentation.bib}
\usepackage{xcolor}
%\pagecolor[rgb]{0.05,0.05,0.05}
%\color[rgb]{0.9,0.9,0.9}

\geometry{margin=1in}
\onehalfspacing

\title{Natural Computation Project Documentation}
\author{Noemi Biancamano \and Davide D'Acunto}
\date{}
\usepackage{listings}
\usepackage{xcolor}

\lstset{
    language=Python,
        basicstyle=\ttfamily\small,
        keywordstyle=\color{blue},
        commentstyle=\color{gray},
        stringstyle=\color{red},
        breaklines=true,
        showstringspaces=false,
        tabsize=4,
        emph={Combine,ParticleSwarmOptimization,ArtificialBeeColony},
        emphstyle=\color{purple}
}
\begin{document}

\maketitle

\begin{abstract}
\noindent The following document compares the performance of different algorithms implemented for solving problems instances generated by the Generalized Numerical Benchmark Generator (GNBG). Two main families of the swarm intelligence algorithms are considered: Particle Swarm Optimization (PSO) and Artificial Bee Colony (ABC).
\end{abstract}
\tableofcontents
\newpage
\section{Introduction}
\subsection{Generalized Numerical Benchmark Generator}
The Generalized Numerical Benchmark Generator (GNBG) is a set of benchmark functions used for evaluating the performance of optimization algorithms. These 24 functions are grouped into three categories of 8 problems each:
\begin{itemize}
    \item \textbf{Unimodal functions}: these functions have a single global minimum, often having a landscape smoother than the other categories and sometimes even convex
    \begin{itemize}
        \item This class evalues how well the algorithm obtains information from the landscape, and how well it exploits this information to converge to the global minimum, since in this case there are not local minima to deceive the algorithm.
    \end{itemize}
    \item \textbf{Single component Multimodal functions}: these functions have multiple local minima, making them more challenging for optimization algorithms since their ability to deceive the algorithms
    \begin{itemize}
        \item This class evaluates how well the algorithm can escape from local minima, and how well it can explore the search space to find the global minimum.
    \end{itemize}
    \item \textbf{Multi component Multimodal functions}: these functions have multiple local minima, but they are more complex than the single component multimodal functions, since they are composed of multiple components, which make the landscape unpredictable and more difficult to navigate
    \begin{itemize}
        \item This class evaluates how well the algorithm can navigate through a complex landscape, and how well it can balance exploration and exploitation to find the global minimum.
    \end{itemize}
    \end{itemize}
\subsection{Particle Swarm Optimization}
The Particle Swarm Optimization (PSO) is a population-based optimization in which a swarm of particles (potential solutions) moves through the search space to find the optimal solution. Each particle adjusts its position based on its own experience and the experience of neighboring particles.
\\[1em]
The update rule for the velocity and position of the $i$-th particle on iteration $t$ in PSO with inertia weight \cite{pso} is given by:
\begin{align*}
\overset{\rightarrow}{v_i}(t+1) &= w \cdot \overset{\rightarrow}{v_i}(t) + \mathcal U(0,c_1) \cdot (\overset{\rightarrow}{p_i} - \overset{\rightarrow}{x_i}(t)) + \mathcal U(0,c_2) \cdot (\overset{\rightarrow}{g_i} - \overset{\rightarrow}{x_i}(t)) \\
\overset{\rightarrow}{x_i}(t+1) &= \overset{\rightarrow}{x_i}(t) + \overset{\rightarrow}{v_i}(t+1)
\end{align*}
In the subsequent sections, each term of the update rule will be explained in detail, along with the parameters involved and their influence on the algorithm's performance.
\subsubsection{Population \& Topology}
A higher population size allows for a more extensive exploration of the search space, but decreases the number of iterations, meanwhile a smaller population size allows for more iterations on fewer particles. The topology affects how particles share information: it oscillates between a global topology, where all particles connected between each other, and a local topology, where particles only interact with few neighbors. 
\\[1em]
The topologies considered in this project are:
\begin{itemize}
    \item \textbf{Random Topology}: particles are connected randomly to $k$ other particles, where $k$ is set to 5 in the experiments. 
    \item \textbf{Star Topology}: all particles are connected to a central particle, which shares the best position to all other particles.
    \item \textbf{Torus Topology}: this topology is a special case of the Von Neumann topology, in which particles are arranged in a 2D grid, and each particle is connected to its four immediate neighbors (up, down, left, right). The Torus topology wraps around, meaning that the particles on the edges are connected to those on the opposite edge, creating a toroidal structure.
\end{itemize}
Since a Torus topology is adopted, the chosen population sizes will be perfect squares, in order to create a square grid of particles. The population sizes considered in the experiments are $121$ and $169$. 
\subsubsection{Position \& Velocity}
The position of each particle represents a potential solution to the problem, while the velocity determines how the particle moves through the search space, with respect to the other parameters. Since the solution space is not $\mathbb R^d$, they must be limited to the range of the problem:
\begin{itemize}
    \item \textbf{Position}: the position of each particle is limited to the range of the problem, which is $[-100, 100]$ for all dimensions. If a particle is going to exceed a boundary, its velocity is shrunk by a factor such that the particle falls on the boundary.
    \item \textbf{Velocity}: the velocity of each particle is limited to a certain range, if the velocity exceeds the maximum (or minimum) velocity, it is clamped to the maximum (or minimum) velocity. The range of the velocity is set to $\pm0.15$ times the difference between the maximum and minimum positions: $\left[-30, 30\right]$. It is important to note that the velocity is independently limited for each dimension. This customization was suggested in \cite{clamp}
\end{itemize}
\subsubsection{Cognitive and Social Weights}
The cognitive and social weights influence respectively the particle's tendency to return to its own best position and the tendency to move towards the best position found by its neighbors. A higher cognitive weight encourages particles to explore the search space more independently, while a higher social weight encourages particles to converge towards the best solution found by the swarm. The values of the cognitive and social weights considered are all combinations of $c_1$ and $c_2$ in $\{0.75, 1.25\}$.
\subsubsection{Inertia}
The inertia weight controls the influence of the previous velocity on the current velocity. It is somewhat similar to the temperature of the particles. In this case other than the standard fixed inertia weight, a linearly decreasing inertia weight is also considered. The inertia weights start from $0.9$ or $0.7$ and eventually if enabled decreases to $0.4$ through the iterations.
\newpage
\subsection{Artificial Bee Colony}
Artificial Bee Colony (ABC) is a swarm intelligence algorithm inspired by the foraging behavior of honey bees.  
The algorithm reproduces how the bees search for food sources, and how they share information about the quality of the food sources with other bees and the process of collecting nectar from the food sources. The ABC algorithm is used for solving optimization problems, even with non linear, multimodal and high dimensional search spaces.

\subsubsection{Bees Types}
The analogy with the behavior of real bees is reflected in the algorithm through the division of the population into three types of bees: employed bees, onlooker bees, and scout bees. Each type of bee has a specific role in the search process:
\begin{itemize}
    \item \textbf{Employed Bees}: these bees are responsible for exploring the search space and exploiting the food sources they have found. Each employed bee is associated with a specific food source, and it shares information about the quality of that food source with the onlooker bees. The employed bees also perform a local search around their associated food source to find better solutions.
    The food sources correspond to potential solutions to the optimization problem, and the quality of a food source is determined by the objective function value of the corresponding solution. 
    \item \textbf{Onlooker Bees}: these bees are responsible for selecting food sources based on the information shared by the employed bees. They choose food sources with a probability proportional to their quality, and they also perform a local search around the selected food source to find better solutions.
    \item \textbf{Scout Bees}: these bees are responsible for exploring the search space randomly to find new food sources. If a food source is abandoned by the employed bees (i.e., it has not been improved for a certain number of iterations), a scout bee is sent to search for a new food source randomly in the search space.
\end{itemize}
Sharing information among the bees occurs in a specific region, called dancing area or hive, where information about food sources are shared through a process called waggle dance. The dancing is proportional to the quality of the food source, so that better food sources are more likely to be selected by the onlooker bees. 
At the beginning, a potential forager starts as unemployed, having no information about the food sources. Than we have to possible outcomes: can become a scout bee and start searching for food sources near the hive, or it can become a recruiter bee, and start following the waggle dance of the employed bees to find a food source. 
After finding a food source, the bee becomes an employed bee, and it starts exploiting the food source, sharing information about its quality with the onlooker bees. After unloading the nectar collected from the food source, the employed bee becomes unemployed again, and it can start searching for new food sources as a scout bee, or it can start following the waggle dance of the employed bees to find a food source as a recruiter bee. 


\subsubsection{Explanation of the analogy}
Now that we know how the algorithm works, we can explain the analogy with the behavior of real bees in more detail. 
In our analogy, the food sources correspond to potential solutions to the optimization problem, and the quality of a food source is determined by the objective function value of the corresponding solution. 

The ABC algorithm can be synthesized as follows:

\paragraph{Initialization:}

a set of candidate solution(employed bees) is randomly generated in the search space, and their quality is evaluated by the objective function. The best solution found so far is stored as the current global best.
So we generate a population of size $N$ of $\{ x_i \}_{i=1}^N$ as follows: 
$$ x_{i,j} = x_{min,j} + rand(0,1) \cdot (x_{max,j} - x_{min,j}),\quad i=1,\ldots,N,\quad j=1,\ldots,D$$
Where $D$ is the dimensionality of the problem, and $x_{min,j}$ and $x_{max,j}$ are the lower and upper bounds of the search space, respectively. 



\paragraph{Employed Bee Phase:}
during the search process, employed bees apply a perturbation to the current solution in order to explore the neighborhood of the current solution, and they evaluate the new solution. Each solution is evaluated by the objective function, and if the new solution is better than the current solution, the employed bee updates its position to the new solution and shares this information with the onlooker bees.(making the solution a global best)
Startin from the current solution $x_i$, an employed bee generates a new solution $v_i$ in the neighborhood of $x_i$ as follows:
$$ v_{i,j} = x_{i,j} + \phi_{i,j} \cdot (x_{i,j} - x_{k,j}),\quad k \neq i$$
\indent where:
\begin{itemize}
    \item $x_K$ is a randomly selected solution from the population, different from $x_i$:
    \item $\phi_{i,j}$ is a random number uniformly distributed in the range $[-1, 1]$;
    \item $j$ is a randomly selected dimension index;
\end{itemize}
Than the new solution $v_i$ is evaluated by the objective function comparing it with the current solution $x_i$. For minimization problems the fiteness of a solution is calculated as follows:
$$ fit_i = \begin{cases}\dfrac{1}{1 + f(x_i)}, & \text{if } f(x_i) \geq 0 \\[10pt]1 + |f(x_i)|, & \text{otherwise}\end{cases} $$
Where $f(x_i)$ is the objective function value. 

\paragraph{Onlooker Bee Phase:}
onlooker bees select a food source based on the information shared by the employed bees, and they apply a perturbation to the selected solution in order to explore the neighborhood of the selected solution, and they evaluate the new solution. If the new solution is better than the selected solution, the onlooker bee updates its position to the new solution and shares this information with the employed bees. (taking the place of the employed bee that found the new solution)
In these phase onlooker bees select a solution $x_i$ with a probability proportional to its fitness:
$$ p_i = \dfrac{fit_i}{\sum_{j=1}^N fit_j} $$
In the original implementation of the algorithm, onlooker bees select a solution by using a roulette wheel selection based on the probabilities $p_i$, probabilist selection can be performed also using ranked selection or tournamente selection.
\paragraph{Scout Bee Phase:}
if an employed bee has not improved its solution for a certain number of iterations, it becomes a scout bee and randomly searches for a new solution in the search space. 

\subsubsection{Popoluation \& Bees Strategy}
In the following sections, the parameters of the ABC algorithm will be explained in detail, along with their influence on the algorithm's performance, putting apart parameters depending on the choosen implementation of the algorithm. 
\\[1em]
The first parameter common in all the optimization algorithms is the population size, which in this case corresponds to the number of bees. A higher population size allows for a more extensive exploration of the search space, while a smaller population size may lead to premature convergence. The population size is typically set to a value that balances exploration and exploitation effectively.
\noindent \\
The number of employed bees is typically set to half of the total population size, while the number of onlooker bees is set to the other half. This allows for a balance between exploration and exploitation, as the employed bees focus on exploiting the current solutions, while the onlooker bees focus on exploring new solutions based on the information shared by the employed bees. The number of scout bees is typically set to a small value, to allow for some random exploration without overwhelming the search process.

\subsubsection{Limit}

The second parameter is the limit, which determines the number of iterations an employed bee can go without improving its solution before it becomes a scout bee. A smaller limit encourages more exploration, while a larger limit allows for more exploitation of the current solutions. The limit is typically set to a value that allows for sufficient exploration without causing excessive random search.






\section{Methods}
In order to compare the performance of the algorithms, statistical tests are performed on the results obtained from the experiments ran on a subset of the problem instances. Based on the type of comparison, i.e. whether many algorithms of the same family are compared among themselves, or whether one algorithm from each family is compared, different tests are performed.
\\[1em]
The methods used for the comparisons will be explained in detail in the following subsections, along with the reason behind their choice. In the next section then the implementation of the methods will be swiftly explained, and finally their planning and execution will be described. The notions are taken from \cite{demsar}.
\subsection{Multiple algorithms of one family comparison}
This case considers the comparison of multiple algorithms of the same family: algorithms belonging to the same family (PSO or ABC) but differing in the parameters used. In this case it is assumed that the algorithms are more than two, and that the results obtained from the experiments are not normally distributed. For this reason, non-parametric tests are performed.
\subsubsection{Friedman Test}
The Friedman test is among the most widely used non-parametric tests for comparing multiple algorithms on multiple datasets, where in this case the dataset consists of the results obtained from the experiments. Its first step is to rank the algorithms on each problem, assigning the rank $1$ to the best performing algorithm, $2$ to the second best, and so on. If two or more algorithms have the same performance, they are assigned the average rank (e.g., if two algorithms are tied for first place, they would both receive a rank of $\dfrac{1+2}2=1.5$).
\\[1em]
After ranking the algorithms on each problem, the mean rank of each algorithm across the considered problems is calculated. This mean rank allows to determine an estimator of the performance of each algorithm which is not affected by the different scales of the results obtained from the different problems. In order to determine whether the observed differences in mean ranks are statistically significant, the Friedman test statistic is calculated: $$Q=\dfrac{12n}{k(k+1)}\sum_{j=1}^{k}\left(\bar r_j-\dfrac{k+1}{2}\right)^2,\qquad \bar r_j=\dfrac1n\sum_{i=1}^n r_{ij},\qquad Q\sim\chi_{(k-1)}^2$$
In the formula, $n$ is the number of problems, $k$ is the number of algorithms, and $\bar r_j$ is the mean rank of the $j$-th algorithm. In order to understand the formula, it is important to explain the intuition behind it. First, the rank $r_{ij}$ itself is distributed accordingly to a discrete uniform distribution. Since under the null hypothesis, all algorithms are expected to perform equally, so they share the same mean rank: $$r_{ij}\sim\mathcal U\left\{1,\ldots,k\right\},\quad \mathbb E\left[r_{ij}\right]=\dfrac{k+1}{2}\overset{H_0}=\mathbb E\left[\bar r_j\right],\quad Var\left[r_{ij}\right]=\dfrac{k^2-1}{12}$$
From which the variance of the mean ranks can be derived: $$Var\left[\bar r_j\right]=Var\left[\dfrac1n\sum_{i=1}^n r_{ij}\right]=\dfrac 1{n^2}\cdot n\dfrac{k^2-1}{12}=\dfrac{k^2-1}{12n}$$
Now, the Friedman test purpose is to measure the deviation of the observed mean ranks from the expected mean rank under the null hypothesis: $$S=\sum_{j=1}^k\left(\bar r_j-\dfrac{k+1}2\right)^2$$
This deviation must then be normalized by the rank variance, in order to be comparable. The Friedman test statistic also introduces one degree of freedom correction because of the covariance between the ranks. In the end, the formula takes the form of a chi-square distribution with $k-1$ degrees of freedom, as shown above. 
\\[1em]
The more the observed mean ranks deviate from the expected mean rank, the higher the value of $Q$, and the more likely it is to reject the null hypothesis. Also, $k$ and $n$ have an influence on the value of $Q$ too: as the number of algorithms $k$ increases, the statistics decreases, while if the number of experiments $n$ increases, the statistic increases.
\subsubsection{Nemenyi post-hoc}
The Friedman test determines whether there are statistically significant differences among the algorithms, but it doesn't specify which algorithms differ. In order to retrieve this information, the Nemenyi post-hoc test is performed. This test purpose is to compare all pairs of algorithms, and determine whether the null hypothesis of equal performance can be rejected for each pair. 
\\[1em]
In order to determine whether the performance of two algorithms $i$ and $j$ is significantly different, the variance of the difference between their mean ranks is calculated: $$Var\left[\bar r_i-\bar r_j\right]=Var\left[\bar r_i\right]+Var\left[\bar r_j\right]-2\ Cov\left[\bar r_i,\bar r_j\right]$$
As aforementioned, the ranks are not independent between themselves: if one algorithm has a high rank on a problem, another algorithm must have a low rank on the same problem. In order to retrieve the covariance between the ranks, some steps must be taken. Knowing that the sum of the ranks on each problem is constant: $$\sum_{j=1}^k r_{ij} = \frac{k(k+1)}{2}\Longrightarrow0=Var\left[\sum_{j=1}^k r_{ij}\right]=\sum_{j=1}^kVar\left[r_{ij}\right]+2\sum_{1\le j<\ell\le k}Cov(r_{ij},r_{i\ell}),\qquad\forall i$$
Solving for the covariance, knowing the variance and knowing that all the covariances are equal, it can be derived that: $$Cov(r_{ij},r_{i\ell})=-\dfrac{k+1}{12},\qquad 1\le j<\ell\le k,\quad\forall i$$
From which the variance of the difference between the mean ranks can be derived: $$Var\left[\bar r_i-\bar r_j\right]=\dfrac{k^2-1}{12n}+\dfrac{k^2-1}{12n}+2\cdot\dfrac{k+1}{12n}=\dfrac{k(k+1)}{6n}$$
This would be sufficient to perform a z-test on the difference between the mean ranks of the two algorithms, but since multiple comparisons are performed, a correction is done by introducing the critical value of the Studentized range distribution $q_\alpha$, which is defined as: $$q=\dfrac{\max\left(Z_i\right)-\min\left(Z_i\right)}{SE\left(Z_i\right)}\qquad q\sim q_{k,\nu}$$
Where $k$ is the number of algorithms, $\nu$ is the degrees of freedom. Since the variances of the mean ranks are known, it is assumed that $\nu=\infty$, meanwhile for the same reason mentioned before, one degree of freedom is detracted from $k$, so the critical value is $q_\alpha=q_{k-1,\infty}(\alpha)$.
\\[1em]
In the end, the performance of two algorithms $i$ and $j$ is significantly different if the absolute difference between their mean ranks is greater than the critical difference: $$|\bar r_i-\bar r_j|>q_\alpha\sqrt{Var\left[\bar r_i-\bar r_j\right]}=q_\alpha\sqrt{\dfrac{k(k+1)}{6n}}=CD$$
This quantity is called the critical difference (CD), and it represents the minimum difference between the mean ranks of two algorithms for their performance to be considered significantly different. As the number of algorithms $k$ increases, the critical difference increases, so it is harder to find significant differences between the algorithms. On the other hand, as the number of problems $n$ increases, the critical difference decreases. The $\alpha$ level also has an influence on the critical difference: as $\alpha$ decreases, the critical value $q_\alpha$ increases.
\subsection{One algorithm for each family comparison}
This case considers the comparison of one algorithm from each family: one PSO and one ABC. In this case, it is assumed that the results obtained from the experiments are not normally distributed. For this reason, non-parametric tests are performed.
\noindent \\
In the next sections, the Wilcoxon test is performed to compare the performance of the two algorithms on each problem, and then a post-hoc comparison is performed to determine whether the observed differences are statistically significant. Its used as an alternative to the paired t-test when the normality assumption is not met.
\subsubsection{Wilcoxon Test}
The Wilcoxon signed-rank test is a non-parametric test used to compare two related samples, in this case the results obtained from the two algorithms on the same problem instances. The test is based on the differences between the paired observations, and it assesses whether the median of these differences is significantly different from zero. 
\\
Considering two algorithms $A$ and $B$, the first step is to calculate the differences between the paired observations: 
$$d_i = A_i - B_i$$ 
where $A_i$ and $B_i$ are the results obtained from the two algorithms on the $i$-th problem instance. Then, the absolute values of these differences are ranked, ignoring any differences that are equal to zero. If there are ties in the absolute differences, they are assigned the average rank (as Friedman ranking). Next, the ranks are assigned a positive or negative sign based on the original differences: if $d_i$ is positive, the rank is positive; if $d_i$ is negative, the rank is negative. 
Under the null hypothesis that there is no difference between the two algorithms, the sum of the positive ranks and the sum of the negative ranks should be approximately equal. The test statistic is then calculated as the smaller of these two sums:
$$W = \min\left(\sum_{d_i > 0} r_i + \dfrac{1}{2} \sum_{d_i = 0} r_i, \sum_{d_i < 0} r_i + \dfrac{1}{2} \sum_{d_i = 0} r_i\right)$$
Where $r_i$ is the rank of the absolute difference $|d_i|$, note that ranks of $d_i = 0$ are split equally between the positive and negative sums. \\
The p-value can be computed considering that under the null hypothesis, all the configuration are equally likely, with probability ${2^{-n}}$, where $n$ is the number of non-zero differences. 
In order to obtain the probability all the configurations of signs for the ranks are counted, and the number of them that lead to a sum of positive ranks (or negative ranks) less than or equal to the observed test statistic $W$ is determined. The p-value is then calculated as:
$$p = \dfrac{\text{\#configurations with } W' \leq W}{2^n}$$
Where $W'$ is the test statistic calculated for each configuration of signs. If the p-value is less than the chosen significance level $\alpha$, the null hypothesis is rejected, indicating that there is a statistically significant difference between the two algorithms. 
For larger sample sizes it is assumed that the distribution of the test statistic $W$ can be approximated by a normal distribution, allowing for the use of a z-test to calculate the p-value. In this case, the test statistic is standardized as follows:
$$Z = \dfrac{W - E[W^+]}{\sqrt{Var(W^+)}}$$
Where $E[W^+]$ and $Var(W^+)$ are the mean and variance of the test
statistic $W$ under the null hypothesis, which can be calculated as:
$$E[W^+] = \dfrac{n(n+1)}{4},\quad Var(W^+) = \dfrac{n(n+1)(2n+1)}{24}$$
The p-value can then be calculated using the standard normal distribution.






\section{Execution}
In the following section, the execution procedure is thoroughly explained, along with the machines used for the experiments.
\\[1em]
Regarding the machines, the experiments were run on the High Performance Computing (HPC) cluster of the University of Salerno, which is composed of $16$ nodes executing Ubuntu Linux $6.8$ mounting each $72$ CPU cores, for a total of $1152$ cores. For this reason, the experiments were parallelized: for each node a process is executed, each one initializes $72$ threads, so that each thread runs an experiment on a different problem instance. In order to distribute the load among the nodes, the experiments are distributed with a job array. It allows to submit a single job to the cluster, which will then replicate itself on each node, but with a different index, so that each node will execute a different subset of the experiments. The results obtained from the experiments are then collected, aggregated, and then analyzed with the statistical tests.
\\[1em]
In order to take into account the maximum execution time of the experiments on the nodes allowed by the cluster policies, the mean time to execute an experiment is estimated to last less than 20 minutes. Since the number of cpus is $1152$, and the maximum time allowed for a job is $9$ hours, the maximum amount of experiments that can be executed in parallel is $1152\cdot\dfrac{9\cdot60}{20}=31104$. This number far exceeds the amount of experiments that will be executed, and in order to avoid overloading the cluster, the experiments are distributed through time on fewer nodes. 
\subsection{Framework}
The framework of the project is implemented in Python, and it is composed of various modules that represent the different components of the algorithms, which were developed independently from each other, in order to split the execution part from the data retrieval and analysis part.
\subsubsection{\texttt{Algorithm.py}}
Through this module, the abstract class that an algorithm must implement is defined. This way by managing the algorithms through a common interface, the execution of the experiments is simplified, and the results can be easily retrieved and analyzed by defining a common format for the results. This module also defines the common parameters of the algorithms, such as the population size, the verbosity level, the number of generations and the seed.
\subsubsection{\texttt{ParticleSwarmOptimization.py}}
The Particle Swarm Optimization (PSO) algorithm is implemented in this module through the Pyswarms library \cite{pyswarms} and the \texttt{Algorithm} abstract class. This library was chosen because it provided a flexible implementation of the PSO algorithm, which exposed the parameters needed for the experiments, the linear decay of the parameters, and the possibility to implement custom topologies. 
\\[1em]
The first part of the file contains literals describing:
\begin{itemize}
    \item The strategy to adopt when a particle is going to exceed the boundaries of the problem
    \item The strategy to adopt when a particle is going to exceed the velocity limits
    \item The strategy to vary the parameters of the algorithm through the iterations
\end{itemize}
Then, the Torus topology is implemented since not available in the library, and finally the PSO algorithm is implemented, which constructor allows to set the parameters previously mentioned.
\subsubsection{\texttt{ArtificialBeeColony.py}}
The Artificial Bee Colony (ABC) algorithm is implemented in this module through the PyABC library \cite{beeoptimal} and the \texttt{Algorithm} abstract class. This library was chosen because it provided a flexible implementation of the ABC algorithm, which exposed the parameters needed for the experiments, and the possibility to implement custom strategies for the employed bees, onlooker bees, and scout bees.
\subsubsection{\texttt{Framework.py}}
The \texttt{Framework} module is responsible for executing and saving the various experiments ran on the different problem instances with the different algorithms and seeds. It allows to execute the experiments in parallel, which results are then saved in a common CSV format, in order to be easily retrieved and analyzed by the other modules.
\subsubsection{\texttt{AggregateCSV.py}}
The following module is responsible for aggregating the results obtained from the various processes and saving them into CSV files: one for each problem, one for each problem class, and one for the overall results. Specifically, the files report results per experiment for individual problems, per experiment and problem within each class, and per experiment, problem, and class for the overall summary.

\subsubsection{\texttt{StatComparison.py}}
\subsection{Parameters combinations}
All the combinations of parameters of the algorithms are written inside the configuration file \texttt{experiments.py}, which is in turn read by the \texttt{Framework} module to execute the experiments. The various parameters combinations are chosen accordingly to the reasoning explained in the previous sections. They make use of a custom class \texttt{Combine} which allows to easily generate all the combinations of the parameters specified in the configuration file. 
\subsubsection{PSO}
By the reasoning explained in the previous sections, the parameters combinations of the PSO algorithm are as follows:
\begin{lstlisting}
[{
    'algorithm': ParticleSwarmOptimization,
    'args': {
        'population': Combine([11*11, 13*13]),
        'topology': Combine(['Random', 'Star', 'Torus']),
        'local_weight': Combine([.75, 1.25]),
        'global_weight': Combine([.75, 1.25]),
        'inertia': Combine([.7, .9]),
        'velocity_clamp': (-.15 * RANGE, .15 * RANGE),
        'end_inertia': Combine([.4, None])
    },
    'name': 'PSO',
}]
\end{lstlisting}
Where \texttt{end\_inertia} is the last value of the inertia weight in case of a linearly decreasing inertia, and \texttt{velocity\_clamp} is the range of the velocity. The other parameters are self-explanatory. The parameters will be referred as such in the following sections.
\\[1em]
Since there are:
\begin{itemize}
    \item Two population sizes
    \item Three topologies
    \item Two local weights
    \item Two global weights
    \item Two inertia weights
    \item Two end inertia weights (including the case of fixed inertia)
    \item One velocity clamp
\end{itemize}
The total number of combinations of parameters for the PSO algorithm is $2\cdot3\cdot2\cdot2\cdot2\cdot2\cdot1=96$, meaning there are $96$ different algorithms to be compared for the PSO family.
\subsubsection{ABC}
\subsection{Planning}
Both the PSO and ABC algorithms undergo the same procedure, since they have almost the same amount of parameters combinations to be tested. The procedure is divided into five main steps. The first step consists in testing all the algorithms on some problems of each class in order to split the algorithms into three subsets: one for each class. The second and third steps consist in filtering, and are executed separately for each class. The continuous filtering helps to obtain more robust results without increasing the number of algorithms to be compared and experiments to be executed.
\\[1em]
In order to have a first type error of $\alpha=0.1$ on the global comparison of the algorithms on each family, for every step the significance level is set to $0.025$, since they will sum up across the steps. The last step is excluded by this procedure, since it is an independent final comparison, and for this reason the significance level is set to $0.05$.
\subsubsection{All algorithms on each class}
All the possible parameters combinations of the algorithms (which will be referred to as "algorithms" for simplicity) are tested on three problems for each class, and for each problem $10$ different seeds are used, in order to obtain $10$ different results (which will be referred as "experiments"). This procedure is applied to all the algorithms of the same family, for each family separately. The results obtained from these experiments are then aggregated by class, which allows to compare the performance of the algorithms with the Friedman ranking.
\\[1em]
For each algorithm the mean rank across the problems of the same class is calculated: $$\bar r_{jc}=\dfrac1{n\cdot m}\sum_{\substack{i=1,\ldots,n\\k=1,\ldots,m}}r_{ijkc}$$
Where $r_{ijkc}$ is the rank of the $j$-th algorithm on the $i$-th problem for the $k$-th seed in the $c$-th class, $n=3$ is the number of problems in the class, and $m=10$ is the number of seeds. Thus, the mean ranks are calculated by averaging the ranks obtained from the different experiments of all the problems and seeds in one class, in order to obtain a more robust estimator of the performance of each algorithm on the class rather than on a single problem.
\\[1em]
Once the mean ranks are calculated, the Friedman test is performed to determine whether there are statistically significant differences among the algorithms. If the null hypothesis is rejected, the Nemenyi post-hoc test is then performed to determine which pairs of algorithms differ significantly in their performance by a critical difference. Otherwise, if the null hypothesis is not rejected, it can be concluded that there are no statistically significant differences among the algorithms on that class of problems, and each algorithm can be considered as good as the others on that class.
\\[1em]
Either way, the results obtained from this procedure allow determining which algorithms perform better and can be selected for the next step, which is the comparison between the remaining algorithms of each class.
\subsubsection{First filtering}
After the first step, a similar procedure is performed this time on the surviving algorithms of each class, and with $30$ seeds for problem, in order to obtain more robust results. The experiments are again aggregated by class and the Friedman test is performed with the Nemenyi post-hoc test, in order to determine a subset of algorithms which performances statistically differ from the others on each class, and that pass to the next step.
\subsubsection{Second filtering}
The very same procedure of the first filtering is performed again, but with $60$ seeds for $6$ problems for each class, in order to obtain even more robust results. The statistical tests are performed again, and the best algorithm is picked for the last selection step. The problems considered in this step are half new and half from the previous step, in order to test the algorithms on new problems while still maintaining some consistency with the previous step.
\\[1em]
In this case, the best algorithm is selected not only on the basis of the statistical tests, but also by considering the mean ranks obtained from the Friedman ranking. This is because statistical tests alone are not able to identify a single best algorithm without further increasing the number of experiments to an extent that cannot be determined a priori, as it depends on the observed differences in mean ranks among the algorithms.
\\[1em]
For this reason, the best algorithm is chosen as the one with the lowest mean rank, among those that are statistically significantly better than the others. It will be improperly referred as the "best algorithm" of the class, even though it is not statistically proven. The statistical tests only allow to determine the best subset of algorithms of that class (or the best algorithm if the subset contains only one algorithm).
\subsubsection{Best algorithms on all classes}
After the second filtering, the best algorithm of each class is selected, and then a final comparison is performed between these three algorithms on all the problems of all the classes, with $100$ seeds for each problem. This time, the mean ranks are not averaged by class, but they are calculated on the overall results obtained from all the problems and seeds, in order to obtain an estimation of the overall performance: $$\bar r_j=\dfrac1{n\cdot m\cdot c}\sum_{\substack{i=1,\ldots,n\\k=1,\ldots,m\\c=1,\ldots,C}}r_{ijkc}$$
Where $C=3$ is the number of classes, and $n$, $m$, and $r_{ijkc}$ are defined as before. The Friedman test is performed again to determine whether there are statistically significant differences among the three algorithms, and if the null hypothesis is rejected, the Nemenyi post-hoc test is performed to determine which pairs of algorithms differ significantly in their performance by a critical difference. Otherwise, if the null hypothesis is not rejected, it can be concluded that there are no statistically significant differences among the three algorithms.
\\[1em] In either case, the algorithm is chosen as the same way as before, which will be improperly referred as the "best algorithm" of the family.
\subsubsection{Final comparison}
\section{Results discussion}
\subsection{PSO}
In the following subsection, the results obtained from the experiments on the PSO algorithms are discussed, along with the influence of the different parameters on the performance of the algorithms in the different classes of problems. The results are discussed separately for each step and each class.
\subsubsection{All algorithms on each class}
Each of the $96$ algorithms is tested on three problems for each class, thus obtaining $96$ mean ranks for each class. In the following tables the mean ranks of the algorithms are reported, for each class.
\begin{longtable}{||cccccc||cc||cc||cc||}
\caption{Risultati aggregati}
\label{tab:results} \\
\hline
    \multicolumn{6}{||c||}{Algorithm parameters}  & \multicolumn{2}{c||}{Class 1} & \multicolumn{2}{c||}{Class 2} & \multicolumn{2}{c||}{Class 3} \\
    \hline
    \hline
    {end\_inertia} & gw & inertia & lw & pop. & topology & Rank & \texttt{1e-8} & Rank & \texttt{1e-8} & Rank & \texttt{1e-8} \\
    \hline
None & 1.25 & 0.70 & 0.75 & 169 & Random & 13.30 & 10 & 15.80 & 0 & 12.50 & 0 \\
0.40 & 1.25 & 0.70 & 0.75 & 169 & Random & 13.30 & 10 & 15.80 & 0 & 12.50 & 0 \\
None & 1.25 & 0.70 & 1.25 & 169 & Random & 12.20 & 10 & 19.10 & 0 & 14.20 & 0 \\
0.40 & 1.25 & 0.70 & 1.25 & 169 & Random & 12.20 & 10 & 19.10 & 0 & 14.20 & 0 \\
0.40 & 1.25 & 0.70 & 0.75 & 121 & Random & 16.30 & 10 & 17.50 & 0 & 12.20 & 1 \\
None & 1.25 & 0.70 & 0.75 & 121 & Random & 16.30 & 10 & 17.50 & 0 & 12.20 & 1 \\
None & 1.25 & 0.70 & 1.25 & 121 & Random & 16.40 & 10 & 20.80 & 0 & 9.00 & 0 \\
0.40 & 1.25 & 0.70 & 1.25 & 121 & Random & 16.40 & 10 & 20.80 & 0 & 9.00 & 0 \\
None & 0.75 & 0.90 & 0.75 & 169 & Torus & 30.70 & 10 & 20.00 & 0 & 13.20 & 0 \\
0.40 & 0.75 & 0.90 & 0.75 & 169 & Torus & 30.70 & 10 & 20.00 & 0 & 13.20 & 0 \\
0.40 & 0.75 & 0.70 & 1.25 & 169 & Random & 16.80 & 10 & 23.00 & 0 & 26.90 & 0 \\
None & 0.75 & 0.70 & 1.25 & 169 & Random & 16.80 & 10 & 23.00 & 0 & 26.90 & 0 \\
None & 0.75 & 0.90 & 0.75 & 121 & Torus & 29.00 & 10 & 16.70 & 0 & 22.70 & 0 \\
0.40 & 0.75 & 0.90 & 0.75 & 121 & Torus & 29.00 & 10 & 16.70 & 0 & 22.70 & 0 \\
None & 0.75 & 0.90 & 0.75 & 121 & Random & 26.10 & 10 & 39.00 & 0 & 16.40 & 0 \\
0.40 & 0.75 & 0.90 & 0.75 & 121 & Random & 26.10 & 10 & 39.00 & 0 & 16.40 & 0 \\
None & 0.75 & 0.70 & 1.25 & 121 & Random & 18.10 & 10 & 29.90 & 0 & 33.80 & 0 \\
0.40 & 0.75 & 0.70 & 1.25 & 121 & Random & 18.10 & 10 & 29.90 & 0 & 33.80 & 0 \\
0.40 & 0.75 & 0.70 & 0.75 & 169 & Random & 15.90 & 10 & 30.60 & 0 & 39.60 & 0 \\
None & 0.75 & 0.70 & 0.75 & 169 & Random & 15.90 & 10 & 30.60 & 0 & 39.60 & 0 \\
None & 0.75 & 0.90 & 1.25 & 121 & Torus & 40.00 & 0 & 26.90 & 0 & 20.80 & 0 \\
0.40 & 0.75 & 0.90 & 1.25 & 121 & Torus & 40.00 & 0 & 26.90 & 0 & 20.80 & 0 \\
0.40 & 1.25 & 0.90 & 0.75 & 121 & Torus & 56.80 & 0 & 19.40 & 0 & 17.40 & 0 \\
None & 1.25 & 0.90 & 0.75 & 121 & Torus & 56.80 & 0 & 19.40 & 0 & 17.40 & 0 \\
None & 0.75 & 0.90 & 0.75 & 169 & Random & 35.80 & 10 & 42.60 & 0 & 16.40 & 0 \\
0.40 & 0.75 & 0.90 & 0.75 & 169 & Random & 35.80 & 10 & 42.60 & 0 & 16.40 & 0 \\
0.40 & 0.75 & 0.90 & 1.25 & 169 & Torus & 46.20 & 0 & 32.40 & 0 & 20.90 & 0 \\
None & 0.75 & 0.90 & 1.25 & 169 & Torus & 46.20 & 0 & 32.40 & 0 & 20.90 & 0 \\
0.40 & 1.25 & 0.90 & 0.75 & 169 & Torus & 60.80 & 0 & 22.20 & 0 & 18.50 & 0 \\
None & 1.25 & 0.90 & 0.75 & 169 & Torus & 60.80 & 0 & 22.20 & 0 & 18.50 & 0 \\
0.40 & 0.75 & 0.70 & 0.75 & 121 & Random & 20.60 & 10 & 36.50 & 0 & 47.80 & 0 \\
None & 0.75 & 0.70 & 0.75 & 121 & Random & 20.60 & 10 & 36.50 & 0 & 47.80 & 0 \\
0.40 & 1.25 & 0.70 & 1.25 & 169 & Torus & 26.00 & 10 & 48.00 & 0 & 51.20 & 0 \\
None & 1.25 & 0.70 & 1.25 & 169 & Torus & 26.00 & 10 & 48.00 & 0 & 51.20 & 0 \\
None & 1.25 & 0.70 & 1.25 & 121 & Torus & 23.80 & 10 & 48.50 & 0 & 55.20 & 0 \\
0.40 & 1.25 & 0.70 & 1.25 & 121 & Torus & 23.80 & 10 & 48.50 & 0 & 55.20 & 0 \\
None & 1.25 & 0.70 & 0.75 & 169 & Torus & 27.90 & 10 & 51.80 & 0 & 61.60 & 0 \\
0.40 & 1.25 & 0.70 & 0.75 & 169 & Torus & 27.90 & 10 & 51.80 & 0 & 61.60 & 0 \\
None & 0.75 & 0.90 & 1.25 & 169 & Random & 61.80 & 0 & 48.20 & 0 & 32.60 & 0 \\
0.40 & 0.75 & 0.90 & 1.25 & 169 & Random & 61.80 & 0 & 48.20 & 0 & 32.60 & 0 \\
0.40 & 1.25 & 0.70 & 0.75 & 121 & Torus & 24.00 & 10 & 57.10 & 0 & 61.70 & 0 \\
None & 1.25 & 0.70 & 0.75 & 121 & Torus & 24.00 & 10 & 57.10 & 0 & 61.70 & 0 \\
None & 0.75 & 0.90 & 1.25 & 121 & Random & 58.80 & 0 & 52.60 & 0 & 33.40 & 0 \\
0.40 & 0.75 & 0.90 & 1.25 & 121 & Random & 58.80 & 0 & 52.60 & 0 & 33.40 & 0 \\
None & 0.75 & 0.90 & 1.25 & 121 & Star & 48.60 & 1 & 53.20 & 0 & 49.10 & 0 \\
0.40 & 0.75 & 0.90 & 1.25 & 121 & Star & 48.60 & 1 & 53.20 & 0 & 49.10 & 0 \\
None & 0.75 & 0.90 & 1.25 & 169 & Star & 50.60 & 0 & 50.40 & 0 & 50.20 & 0 \\
0.40 & 0.75 & 0.90 & 1.25 & 169 & Star & 50.60 & 0 & 50.40 & 0 & 50.20 & 0 \\
None & 0.75 & 0.70 & 1.25 & 169 & Torus & 31.70 & 10 & 54.60 & 0 & 66.60 & 0 \\
0.40 & 0.75 & 0.70 & 1.25 & 169 & Torus & 31.70 & 10 & 54.60 & 0 & 66.60 & 0 \\
0.40 & 0.75 & 0.70 & 1.25 & 121 & Torus & 30.10 & 10 & 55.40 & 0 & 70.60 & 0 \\
None & 0.75 & 0.70 & 1.25 & 121 & Torus & 30.10 & 10 & 55.40 & 0 & 70.60 & 0 \\
0.40 & 1.25 & 0.90 & 1.25 & 121 & Torus & 77.50 & 0 & 44.70 & 0 & 35.10 & 0 \\
None & 1.25 & 0.90 & 1.25 & 121 & Torus & 77.50 & 0 & 44.70 & 0 & 35.10 & 0 \\
0.40 & 1.25 & 0.90 & 0.75 & 121 & Random & 73.40 & 0 & 46.80 & 0 & 42.00 & 0 \\
None & 1.25 & 0.90 & 0.75 & 121 & Random & 73.40 & 0 & 46.80 & 0 & 42.00 & 0 \\
None & 0.75 & 0.70 & 0.75 & 169 & Torus & 33.30 & 10 & 58.40 & 0 & 70.80 & 0 \\
0.40 & 0.75 & 0.70 & 0.75 & 169 & Torus & 33.30 & 10 & 58.40 & 0 & 70.80 & 0 \\
None & 1.25 & 0.90 & 1.25 & 169 & Torus & 78.20 & 0 & 50.10 & 0 & 35.60 & 0 \\
0.40 & 1.25 & 0.90 & 1.25 & 169 & Torus & 78.20 & 0 & 50.10 & 0 & 35.60 & 0 \\
0.40 & 1.25 & 0.90 & 0.75 & 169 & Random & 73.30 & 0 & 48.20 & 0 & 44.50 & 0 \\
None & 1.25 & 0.90 & 0.75 & 169 & Random & 73.30 & 0 & 48.20 & 0 & 44.50 & 0 \\
0.40 & 0.75 & 0.70 & 0.75 & 121 & Torus & 30.50 & 10 & 62.20 & 0 & 78.20 & 0 \\
None & 0.75 & 0.70 & 0.75 & 121 & Torus & 30.50 & 10 & 62.20 & 0 & 78.20 & 0 \\
None & 0.75 & 0.90 & 0.75 & 121 & Star & 38.30 & 1 & 64.50 & 0 & 71.60 & 0 \\
0.40 & 0.75 & 0.90 & 0.75 & 121 & Star & 38.30 & 1 & 64.50 & 0 & 71.60 & 0 \\
0.40 & 0.75 & 0.90 & 0.75 & 169 & Star & 37.70 & 1 & 66.40 & 0 & 71.80 & 0 \\
None & 0.75 & 0.90 & 0.75 & 169 & Star & 37.70 & 1 & 66.40 & 0 & 71.80 & 0 \\
0.40 & 1.25 & 0.90 & 1.25 & 169 & Random & 79.60 & 0 & 53.40 & 0 & 46.60 & 0 \\
None & 1.25 & 0.90 & 1.25 & 169 & Random & 79.60 & 0 & 53.40 & 0 & 46.60 & 0 \\
None & 1.25 & 0.90 & 1.25 & 121 & Random & 82.00 & 0 & 52.80 & 0 & 46.20 & 0 \\
0.40 & 1.25 & 0.90 & 1.25 & 121 & Random & 82.00 & 0 & 52.80 & 0 & 46.20 & 0 \\
None & 1.25 & 0.90 & 0.75 & 121 & Star & 64.80 & 0 & 67.60 & 0 & 55.20 & 0 \\
0.40 & 1.25 & 0.90 & 0.75 & 121 & Star & 64.80 & 0 & 67.60 & 0 & 55.20 & 0 \\
None & 1.25 & 0.90 & 0.75 & 169 & Star & 68.00 & 0 & 63.80 & 0 & 57.40 & 0 \\
0.40 & 1.25 & 0.90 & 0.75 & 169 & Star & 68.00 & 0 & 63.80 & 0 & 57.40 & 0 \\
None & 1.25 & 0.70 & 1.25 & 169 & Star & 56.80 & 0 & 63.70 & 0 & 83.80 & 0 \\
0.40 & 1.25 & 0.70 & 1.25 & 169 & Star & 56.80 & 0 & 63.70 & 0 & 83.80 & 0 \\
None & 1.25 & 0.90 & 1.25 & 169 & Star & 80.50 & 0 & 66.00 & 0 & 58.80 & 0 \\
0.40 & 1.25 & 0.90 & 1.25 & 169 & Star & 80.50 & 0 & 66.00 & 0 & 58.80 & 0 \\
None & 1.25 & 0.90 & 1.25 & 121 & Star & 81.40 & 0 & 71.40 & 0 & 57.60 & 0 \\
0.40 & 1.25 & 0.90 & 1.25 & 121 & Star & 81.40 & 0 & 71.40 & 0 & 57.60 & 0 \\
0.40 & 1.25 & 0.90 & 1.25 & 121 & Star & 81.40 & 0 & 71.40 & 0 & 57.60 & 0 \\
None & 1.25 & 0.70 & 1.25 & 121 & Star & 60.80 & 0 & 70.70 & 0 & 82.20 & 0 \\
0.40 & 1.25 & 0.70 & 1.25 & 121 & Star & 60.80 & 0 & 70.70 & 0 & 82.20 & 0 \\
None & 1.25 & 0.70 & 0.75 & 169 & Star & 64.80 & 0 & 72.20 & 0 & 85.50 & 0 \\
0.40 & 1.25 & 0.70 & 0.75 & 169 & Star & 64.80 & 0 & 72.20 & 0 & 85.50 & 0 \\
None & 1.25 & 0.70 & 0.75 & 121 & Star & 70.70 & 0 & 75.20 & 0 & 86.80 & 0 \\
0.40 & 1.25 & 0.70 & 0.75 & 121 & Star & 70.70 & 0 & 75.20 & 0 & 86.80 & 0 \\
None & 0.75 & 0.70 & 1.25 & 169 & Star & 80.70 & 0 & 69.70 & 0 & 84.30 & 0 \\
0.40 & 0.75 & 0.70 & 1.25 & 169 & Star & 80.70 & 0 & 69.70 & 0 & 84.30 & 0 \\
None & 0.75 & 0.70 & 1.25 & 121 & Star & 85.40 & 0 & 68.80 & 0 & 82.40 & 0 \\
0.40 & 0.75 & 0.70 & 1.25 & 121 & Star & 85.40 & 0 & 68.80 & 0 & 82.40 & 0 \\
None & 0.75 & 0.70 & 0.75 & 169 & Star & 85.00 & 0 & 80.00 & 0 & 87.30 & 0 \\
0.40 & 0.75 & 0.70 & 0.75 & 169 & Star & 85.00 & 0 & 80.00 & 0 & 87.30 & 0 \\
0.40 & 0.75 & 0.70 & 0.75 & 121 & Star & 87.20 & 0 & 79.20 & 0 & 89.70 & 0 \\
None & 0.75 & 0.70 & 0.75 & 121 & Star & 87.20 & 0 & 79.20 & 0 & 89.70 & 0 \\
\hline
\end{longtable}
\subsection{ABC}
\subsection{PSO vs ABC}

\section{Conclusion}

\printbibliography

\end{document}